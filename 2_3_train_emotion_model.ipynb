{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Plan of Action\n",
        "\n",
        "*   **CK+ Dataset images** are stored **in separate folders,** named basis their emotion labels:\n",
        " *   0 = 'anger', 1 = 'contempt',  2 = 'disgust',    3 = 'fear',    4 = 'happy',    5 = 'sadness',    6 = 'surprise'\n",
        "\n",
        "* Convert all images to **grayscale**\n",
        "* **Define emotion labels** basis use case\n",
        "* Using **X epochs** on our **defined CNN Architecture**, comprising of:\n",
        "    - an input *Conv2D* layer (with 32 filters) paired with an *MaxPooling2D* layer,\n",
        "    - 3 pairs of *Conv2D* (with 64, 128 & 256 filters) and *MaxPooling2D* layers,\n",
        "    - 1 *Dense* layer with 128 nodes, and\n",
        "    - an output *Dense* layer with 3 nodes."
      ],
      "metadata": {
        "id": "tLGJG4wgBJh-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mount Google Drive"
      ],
      "metadata": {
        "id": "sJKx5m2v-T2h"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "b1ewyp9xrmll",
        "outputId": "1003253e-02c9-4c74-a560-0a4753b5554e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d5df0069828e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    131\u001b[0m   )\n\u001b[1;32m    132\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OiVGzDoR2qu",
        "outputId": "dd60fb22-89b3-4eb1-990b-24c3a2cc04b5"
      },
      "source": [
        "%cd /content/drive/MyDrive/emotion_input_output\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/emotion_input_output'\n",
            "/content\n",
            "drive  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraties/ Functions"
      ],
      "metadata": {
        "id": "WbYsPwuj-eU5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Flatten,BatchNormalization\n",
        "from tensorflow.keras.layers import Dense, MaxPooling2D,Conv2D\n",
        "from tensorflow.keras.layers import Input,Activation,Add\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from keras.models import Sequential,load_model,Model\n",
        "from keras.layers import Conv2D,MaxPool2D,Dense,Dropout,BatchNormalization,Flatten,Input\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "L4yOK4K-1Bjh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Dataset"
      ],
      "metadata": {
        "id": "QIt_obba-lir"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6vupcIrTHts",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "5122bd0a-4639-4f54-ea99-c10571932a27"
      },
      "source": [
        "dataset_folder='input/CK+48'\n",
        "sub_folders=os.listdir(dataset_folder)\n",
        "\n",
        "sub_folders"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'input/CK+48'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-8b8c22195099>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdataset_folder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'input/CK+48'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msub_folders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msub_folders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'input/CK+48'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zlynqGGTTw8"
      },
      "source": [
        "# Reading folder names as labels and images underneath\n",
        "i=0\n",
        "last=[]\n",
        "images=[]\n",
        "labels=[]\n",
        "temp = sub_folders\n",
        "\n",
        "# reading folders in the main dataset folder, one at a time\n",
        "for sub_folder in sub_folders:\n",
        "  sub_folder_index = temp.index(sub_folder)\n",
        "  label = sub_folder_index\n",
        "\n",
        "  # Define labels basis use case. We are using positive:0, negative:1, neutral:2\n",
        "  # for our use case of predicting emotions of visitors entering a retail store\n",
        "  if  label in [4, 6]:    # label in ['happy', 'surprise']\n",
        "    new_label=0           # changed to label = positive emotion\n",
        "  elif label in [0,5]:      # label in ['anger','sadness']\n",
        "    new_label=1           # changed to label = negative emotion\n",
        "  else:                   # label in ['contempt', 'disgust', 'fear']\n",
        "    new_label=2           # changed to label = neutral emotion\n",
        "\n",
        "\n",
        "  path = dataset_folder+'/'+sub_folder\n",
        "  sub_folder_images= os.listdir(path)\n",
        "\n",
        "  # reading images in the sub folder, one at a time\n",
        "  for image in sub_folder_images:\n",
        "    image_path = path+'/'+image\n",
        "    print(image_path+\"\\t\"+str(new_label))\n",
        "\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    image= cv2.resize(image,(48,48))\n",
        "    images.append(image)\n",
        "    labels.append(new_label)\n",
        "    i+=1\n",
        "  last.append(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynAXG1LwUkds"
      },
      "source": [
        "images_x = np.array(images)\n",
        "labels_y = np.array(labels)\n",
        "\n",
        "# we divide image pixels by 255 to reduce computation power\n",
        "images_x = images_x/255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2IAQCpvUozE"
      },
      "source": [
        "images_x.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2zL4UzAUpUq"
      },
      "source": [
        "# encoding the labels\n",
        "num_of_classes = 3\n",
        "labels_y_encoded = tf.keras.utils.to_categorical(labels_y,num_classes=num_of_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split into Train / Test"
      ],
      "metadata": {
        "id": "FuhOMQUWO51n"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65f5AH0TUtWA"
      },
      "source": [
        "X_train, X_test, Y_train, Y_test= train_test_split(images_x, labels_y_encoded,test_size=0.25, random_state=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_train)"
      ],
      "metadata": {
        "id": "9dm-l3cG7n6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_test)"
      ],
      "metadata": {
        "id": "2QIGnxnV7seC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define CNN Architecture"
      ],
      "metadata": {
        "id": "wckM9wr2PDcZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input = Input(shape = (48,48,1))\n",
        "\n",
        "conv1 = Conv2D(32,(3, 3), padding = 'same', strides=(1, 1), kernel_regularizer=l2(0.001))(input)\n",
        "conv1 = Dropout(0.1)(conv1)\n",
        "conv1 = Activation('relu')(conv1)\n",
        "pool1 = MaxPooling2D(pool_size = (2,2)) (conv1)\n",
        "\n",
        "conv2 = Conv2D(64,(3, 3), padding = 'same', strides=(1, 1), kernel_regularizer=l2(0.001))(pool1)\n",
        "conv2 = Dropout(0.1)(conv2)\n",
        "conv2 = Activation('relu')(conv2)\n",
        "pool2 = MaxPooling2D(pool_size = (2,2)) (conv2)\n",
        "\n",
        "conv3 = Conv2D(128,(3, 3), padding = 'same', strides=(1, 1), kernel_regularizer=l2(0.001))(pool2)\n",
        "conv3 = Dropout(0.1)(conv3)\n",
        "conv3 = Activation('relu')(conv3)\n",
        "pool3 = MaxPooling2D(pool_size = (2,2)) (conv3)\n",
        "\n",
        "conv4 = Conv2D(256,(3, 3), padding = 'same', strides=(1, 1), kernel_regularizer=l2(0.001))(pool3)\n",
        "conv4 = Dropout(0.1)(conv4)\n",
        "conv4 = Activation('relu')(conv4)\n",
        "pool4 = MaxPooling2D(pool_size = (2,2)) (conv4)\n",
        "\n",
        "flatten = Flatten()(pool4)\n",
        "\n",
        "dense_1 = Dense(128,activation='relu')(flatten)\n",
        "\n",
        "drop_1 = Dropout(0.2)(dense_1)\n",
        "\n",
        "output = Dense(3,activation=\"sigmoid\")(drop_1)"
      ],
      "metadata": {
        "id": "5PXrZpjVQkJZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(inputs=input,outputs=output)\n",
        "model.compile(optimizer=\"adam\", loss=[\"categorical_crossentropy\"], metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "YJlKlbWEVt5i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training"
      ],
      "metadata": {
        "id": "5dPSD8THePCg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fle_s='./output/emotion_model.h5'\n",
        "checkpointer = ModelCheckpoint(fle_s, monitor='loss',verbose=1,save_best_only=True,\n",
        "                               save_weights_only=False, mode='auto',save_freq='epoch')\n",
        "callback_list=[checkpointer]"
      ],
      "metadata": {
        "id": "a5Z2BPo8aaWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save = model.fit(X_train,Y_train,batch_size=32,validation_data=(X_test,Y_test),epochs=50,callbacks=[callback_list])"
      ],
      "metadata": {
        "id": "r-5peV5-a6LZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict function ( please check how it works with the dataset )\n",
        "\n",
        "Also emotion1, emotion2, emotion3 should be updated\n",
        "\n",
        "Requires to download the model or refer to an existing one\n",
        "\n",
        "##Please check!!!\n"
      ],
      "metadata": {
        "id": "Pad-TfyS5QAI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing import image\n",
        "import cv2\n",
        "\n",
        "# Load your trained model\n",
        "# model = load_model('path_to_your_model.h5')\n",
        "\n",
        "# Define emotion labels corresponding to the output of your model\n",
        "emotions = ['Emotion1', 'Emotion2', 'Emotion3']  # Replace with actual emotion labels\n",
        "\n",
        "def preprocess_image(img_path):\n",
        "    # Load the image\n",
        "    img = cv2.imread(img_path)\n",
        "\n",
        "    # Resize the image to 48x48 pixels\n",
        "    img = cv2.resize(img, (48, 48))\n",
        "\n",
        "    # Convert to grayscale\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Normalize pixel values to [0, 1]\n",
        "    img = img.astype('float32') / 255.0\n",
        "\n",
        "    # Expand dimensions to match input shape (1, 48, 48, 1)\n",
        "    img = np.expand_dims(img, axis=-1)  # Add channel dimension\n",
        "    img = np.expand_dims(img, axis=0)   # Add batch dimension\n",
        "\n",
        "    return img\n",
        "\n",
        "def predict(img_path):\n",
        "    # Preprocess the image\n",
        "    processed_image = preprocess_image(img_path)\n",
        "\n",
        "    # Make prediction\n",
        "    predictions = model.predict(processed_image)\n",
        "\n",
        "    # Assuming the output is in the form of probabilities for each class\n",
        "    predicted_emotion_index = np.argmax(predictions[0])  # Get index of the highest score\n",
        "\n",
        "    # Get the corresponding emotion label\n",
        "    predicted_emotion = emotions[predicted_emotion_index]\n",
        "\n",
        "    return predicted_emotion\n",
        "\n",
        "# Example usage:\n",
        "# emotion = predict('path_to_image.jpg')\n",
        "# print(f'Predicted Emotion: {emotion}')\n"
      ],
      "metadata": {
        "id": "0x91orIq5MGu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Version for a set of images, function will make predictions for many pictures"
      ],
      "metadata": {
        "id": "ynRAcWcy-_Po"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "def load_and_preprocess_image(img_path, target_size=(48, 48)):\n",
        "    \"\"\"Load and preprocess a single image.\"\"\"\n",
        "    img = image.load_img(img_path, target_size=target_size, color_mode='grayscale')\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=-1)  # Ensure it has shape (48, 48, 1)\n",
        "    img_array = img_array / 255.0  # Normalize to [0, 1]\n",
        "    return img_array\n",
        "\n",
        "def predict_emotion(image_array, model):\n",
        "    \"\"\"Predict the emotion for a single image array.\"\"\"\n",
        "    preds = model.predict(np.expand_dims(image_array, axis=0))  # Add batch dimension\n",
        "    predicted_class = np.argmax(preds, axis=1)  # Get the index of the highest score\n",
        "    return predicted_class[0]  # Return the class index\n",
        "\n",
        "def predict_images_in_folder(folder_path, model):\n",
        "    \"\"\"Predict emotions for all images in a specified folder.\"\"\"\n",
        "    predictions = {}\n",
        "\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if filename.endswith(('.png', '.jpg', '.jpeg')):  # Check for image file extensions\n",
        "            img_path = os.path.join(folder_path, filename)\n",
        "            img_array = load_and_preprocess_image(img_path)\n",
        "\n",
        "            # Make prediction\n",
        "            predicted_class = predict_emotion(img_array, model)\n",
        "            predictions[filename] = predicted_class  # Store the predicted class\n",
        "\n",
        "    return predictions\n",
        "\n",
        "# Example usage:\n",
        "# Load your trained model (update the path accordingly)\n",
        "model = load_model('path_to_your_model.h5')\n",
        "\n",
        "# Specify the folder containing images\n",
        "folder_path = 'path_to_your_image_folder'\n",
        "\n",
        "# Get predictions\n",
        "predictions = predict_images_in_folder(folder_path, model)\n",
        "\n",
        "# Print predictions\n",
        "for img_name, pred in predictions.items():\n",
        "    print(f'Image: {img_name}, Predicted Class: {pred}')\n"
      ],
      "metadata": {
        "id": "zWFNTMtq-9vy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Performance"
      ],
      "metadata": {
        "id": "9Ps9uoF9ejS9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the train and test loss and accuracy values from the neural network above.\n",
        "\n",
        "train_loss = save.history['loss']\n",
        "test_loss = save.history['val_loss']\n",
        "train_accuracy = save.history['accuracy']\n",
        "test_accuracy = save.history['val_accuracy']"
      ],
      "metadata": {
        "id": "w-8TBOYjengQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting a line chart to visualize the loss and accuracy values by epochs.\n",
        "\n",
        "fig, ax = plt.subplots(ncols=2, figsize=(15,7))\n",
        "\n",
        "ax = ax.ravel()\n",
        "\n",
        "ax[0].plot(train_loss, label='Train Loss', color='royalblue', marker='o', markersize=5)\n",
        "ax[0].plot(test_loss, label='Test Loss', color = 'orangered', marker='o', markersize=5)\n",
        "\n",
        "ax[0].set_xlabel('Epochs', fontsize=14)\n",
        "ax[0].set_ylabel('Categorical Crossentropy', fontsize=14)\n",
        "\n",
        "ax[0].legend(fontsize=14)\n",
        "ax[0].tick_params(axis='both', labelsize=12)\n",
        "\n",
        "ax[1].plot(train_accuracy, label='Train Accuracy', color='royalblue', marker='o', markersize=5)\n",
        "ax[1].plot(test_accuracy, label='Test Accuracy', color='orangered', marker='o', markersize=5)\n",
        "\n",
        "ax[1].set_xlabel('Epochs', fontsize=14)\n",
        "ax[1].set_ylabel('Accuracy', fontsize=14)\n",
        "\n",
        "ax[1].legend(fontsize=14)\n",
        "ax[1].tick_params(axis='both', labelsize=12)\n",
        "\n",
        "fig.suptitle(x=0.5, y=0.92, t=\"Lineplots showing loss and accuracy of CNN model by epochs\", fontsize=16)"
      ],
      "metadata": {
        "id": "CSMBtxOZerhx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YscIu-bF5LDg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}